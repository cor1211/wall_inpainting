# LoRA Training Configuration for Wall Inpainting

model:
  pretrained_model_name_or_path: "runwayml/stable-diffusion-inpainting"
  revision: null
  variant: null
  
  # LoRA parameters
  lora_rank: 8                    # Low-rank dimension (4-16 typical)
  lora_alpha: 16                  # Scaling factor (usually 2x rank)
  lora_dropout: 0.0               # Dropout for LoRA layers
  target_modules:                 # UNet attention layers to apply LoRA
    - "to_k"
    - "to_q" 
    - "to_v"
    - "to_out.0"

dataset:
  train_data_dir: "training_ready/train"
  validation_data_dir: "training_ready/validation"
  resolution: 512
  center_crop: true
  random_flip: true
  quality_threshold: 0.6          # Increased to filter noisy masks (was 0.5)
  dataloader_num_workers: 4

# Reference Image Generation (NEW - for color fidelity)
reference:
  # Color extraction method: "median" (robust), "mean" (fast), "kmeans" (accurate but slow)
  color_extraction_method: "median"
  
  # HYBRID STRATEGY: Mix extracted colors with random colors
  # 0.0 = only extracted (realistic), 1.0 = only random (maximum generalization)
  random_color_prob: 0.3          # 30% random, 70% extracted (recommended)
  
  # Color jitter for data augmentation
  color_jitter_prob: 0.2          # 20% chance of slight color variation
  color_jitter_range: 15.0        # Max LAB space jitter
  
  # Texture for CLIP feature extraction
  add_reference_texture: true
  texture_noise_std: 8.0
  add_lighting_gradient: true
  
  # Mask erosion to reduce segmentation noise
  mask_erosion_size: 5            # Kernel size (0 = disabled, 5-7 recommended)

training:
  # Batch settings (optimal for 12GB VRAM - RTX 3060 Ti)
  train_batch_size: 4             # Optimal throughput: 3.99s/step
  gradient_accumulation_steps: 2  # Effective batch = 8
  # Effective batch size = 4 * 2 = 8
  
  # Learning rate
  learning_rate: 1.0e-4
  lr_scheduler: "cosine"
  lr_warmup_steps: 500
  lr_num_cycles: 1
  
  # Training duration
  num_train_epochs: 10
  max_train_steps: 15000          # ~1.26 epochs with 11.8k samples
  
  # Optimization (VRAM optimized)
  use_8bit_adam: true             # Saves ~1-2GB VRAM
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay: 1.0e-2
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
  
  # Mixed precision
  mixed_precision: "fp16"
  gradient_checkpointing: true    # Saves ~30-40% VRAM
  
  # Memory optimization  
  enable_xformers: true           # Saves ~20-30% VRAM if available
  enable_vae_slicing: true        # Process VAE in slices
  enable_vae_tiling: true         # Process large images in tiles
  
  # Reproducibility
  seed: 42
  
  # Zero-Prompt Strategy: Set to true to remove text prompts and force
  # the model to rely solely on image conditioning (IP-Adapter, mask, depth)
  unconditional_training: true   # Enable for color fidelity experiment

checkpointing:
  output_dir: "lora_checkpoints"
  checkpointing_steps: 1000
  resume_from_checkpoint: /mnt/data1tb/vinh/wall_inpainting/lora_checkpoints/checkpoint-2000    # Path to resume from
  
validation:
  validation_steps: 500           # Generate samples every N steps
  num_validation_samples: 50      # Increased for rigorous color fidelity assessment
  samples_per_sheet: 10           # Number of samples per validation grid sheet
  validation_prompts:
    - "interior room with beige walls, professional photography"
    - "a room with terracotta painted walls, modern interior"
    - "gray walls in elegant living room"
    - "dusty rose walls in cozy bedroom"

logging:
  report_to: "tensorboard"        # "tensorboard", "wandb", or "none"
  logging_dir: "logs"
  log_with_wandb: false
  wandb_project: "wall-inpainting-lora"

# ========== IP-ADAPTER INTEGRATION (NEW) ==========
# Following Paint-by-Example and AnyDoor approach:
# Train LoRA with IP-Adapter ACTIVE (but FROZEN) so LoRA learns to use reference
ip_adapter:
  enabled: true                   # Enable IP-Adapter during training
  model_id: "h94/IP-Adapter"      # IP-Adapter model ID
  weight_name: "ip-adapter_sd15.bin"  # Standard IP-Adapter (ViT-L/14, 768 dim)
  scale: 1.0                      # Full strength reference conditioning
  freeze_weights: true            # IMPORTANT: Freeze IP-Adapter, only train LoRA

# Optional: Color Consistency Loss
# Adds explicit color matching loss on masked region
color_loss:
  enabled: true                   # Enable color loss
  weight: 0.1                     # Weight relative to noise loss
  start_step: 500                 # Start applying after model converges basic
