# Training Strategy Fixes - Chi Tiáº¿t CÃ¡c Thay Äá»•i

> **NgÃ y:** 2026-02-07  
> **File:** `train.py`  
> **Má»¥c Ä‘Ã­ch:** TÃ i liá»‡u chi tiáº¿t cÃ¡c thay Ä‘á»•i Ä‘á»ƒ tuÃ¢n thá»§ training strategy má»›i

---

## ğŸ“‹ TÃ³m Táº¯t Thay Äá»•i

### âœ… ÄÃ£ Sá»­a

1. **Training Strategy** - Sá»­a logic training Ä‘á»ƒ há»c Ä‘á»•i mÃ u thay vÃ¬ reconstruct
2. **ControlNet Type** - Äá»•i tá»« Canny sang Depth
3. **Dataset Configuration** - Cáº¥u hÃ¬nh Ä‘Ãºng cho training strategy má»›i
4. **Validation Function** - Sá»­a Ä‘á»ƒ match vá»›i training logic
5. **Learning Rate Scheduler** - ThÃªm LR scheduler
6. **Checkpointing** - Cáº£i thiá»‡n checkpoint saving
7. **Comments** - ThÃªm comments chi tiáº¿t cho tá»«ng phase

---

## ğŸ”§ Chi Tiáº¿t CÃ¡c Thay Äá»•i

### 1. Training Strategy (CRITICAL FIX)

#### âŒ TrÆ°á»›c (SAI):
```python
# DÃ¹ng target lÃ m GT nhÆ°ng khÃ´ng rÃµ rÃ ng vá» strategy
pixel_values = batch["targets"]  # KhÃ´ng rÃµ lÃ  target hay source
```

#### âœ… Sau (ÄÃšNG):
```python
# RÃµ rÃ ng: DÃ¹ng TARGET image (new wall color) lÃ m GT
target_pixel_values = batch["target"]  # TARGET = new color
target_latents = vae.encode(target_pixel_values_normalized)  # Encode TARGET
noisy_latents = noise_scheduler.add_noise(target_latents, noise, timesteps)  # Add noise to TARGET
```

**Logic:**
- **Input (noisy)**: Target image (áº£nh tÆ°á»ng má»›i) - ÄÃ¢y lÃ  key!
- **Conditions**:
  - ControlNet: Source image (áº£nh tÆ°á»ng cÅ©) â†’ preserve structure
  - IP-Adapter: Color reference (mÃ u má»›i) â†’ transfer color
  - Masked source: Source image (áº£nh tÆ°á»ng cÅ©) â†’ inpainting context
- **Target (GT)**: Target image (áº£nh tÆ°á»ng má»›i)

### 2. ControlNet Type

#### âŒ TrÆ°á»›c:
```python
parser.add_argument("--controlnet_model", default="lllyasviel/control_v11p_sd15_canny")
```

#### âœ… Sau:
```python
parser.add_argument("--controlnet_model", default="lllyasviel/control_v11f1p_sd15_depth")
```

**LÃ½ do:** Depth tá»‘t hÆ¡n Canny cho structure preservation trong wall recoloring.

### 3. Dataset Configuration

#### âŒ TrÆ°á»›c:
```python
train_dataset = WallPaintDataset(
    data_json=args.data_json,
    image_size=args.resolution,
    reconstruction_ratio=0.5  # 50% reconstruct source, 50% use target
)
```

#### âœ… Sau:
```python
train_dataset = WallPaintDataset(
    data_json=args.data_json,
    image_size=args.resolution,
    reconstruction_ratio=0.0,  # Always use target (new color) as GT
    use_depth=True,  # Use depth map for ControlNet
    use_canny=False,
    random_flip=True
)
```

**LÃ½ do:** 
- `reconstruction_ratio=0.0`: LuÃ´n dÃ¹ng target (new color) lÃ m GT, khÃ´ng reconstruct source
- `use_depth=True`: DÃ¹ng depth map thay vÃ¬ canny

### 4. Training Loop - PhÃ¢n Chia RÃµ RÃ ng CÃ¡c Phase

#### âœ… Phase 1: Prepare Target Latents
```python
# Encode TARGET image (new wall color) to latent space
target_pixel_values = batch["target"].to(dtype=weight_dtype)
target_pixel_values_normalized = target_pixel_values * 2.0 - 1.0
target_latents = vae.encode(target_pixel_values_normalized).latent_dist.sample()
target_latents = target_latents * vae.config.scaling_factor
```

#### âœ… Phase 2: Add Noise to Target
```python
# Sample noise and add to TARGET latents
noise = torch.randn_like(target_latents)  # Îµ ~ N(0, I) - GT for loss
timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,))
noisy_latents = noise_scheduler.add_noise(target_latents, noise, timesteps)
```

#### âœ… Phase 3: Prepare Conditions
```python
# A. Text Embeddings
encoder_hidden_states = text_encoder(inputs.input_ids.to(device))[0]

# B. ControlNet: Use SOURCE image (old wall) for structure
control_images_normalized = batch["conditional_images"] * 2.0 - 1.0
down_block_res_samples, mid_block_res_sample = controlnet(
    noisy_latents,  # Noisy TARGET latents
    timesteps,
    encoder_hidden_states=encoder_hidden_states,
    controlnet_cond=control_images_normalized,  # Depth from SOURCE
)

# C. IP-Adapter: Use COLOR REFERENCE (new color) for color transfer
pixel_values_ip = batch["color_patches"]  # Color reference
image_embeds = image_encoder(pixel_values_ip_normalized).image_embeds
added_cond_kwargs = {"image_embeds": image_embeds}
```

#### âœ… Phase 4: Prepare Inpainting Inputs
```python
# Use SOURCE image (old wall) for masked_source
masked_source_pixel = batch["masked_sources"]  # SOURCE with mask applied
masked_latents = vae.encode(masked_source_pixel_normalized).latent_dist.sample()

# Concatenate: [noisy_latents, mask, masked_source_latents]
unet_input = torch.cat([noisy_latents, mask_latents, masked_latents], dim=1)
```

#### âœ… Phase 5: UNet Prediction
```python
# UNet predicts noise added to TARGET latents
noise_pred = unet(
    unet_input,
    timesteps,
    encoder_hidden_states=encoder_hidden_states,  # Text
    down_block_additional_residuals=down_block_res_samples,  # ControlNet (structure)
    mid_block_additional_residual=mid_block_res_sample,  # ControlNet (structure)
    added_cond_kwargs=added_cond_kwargs  # IP-Adapter (color)
).sample
```

#### âœ… Phase 6: Loss Computation
```python
# Loss: MSE between predicted noise and actual noise
# Model learns to predict noise added to TARGET image
loss = F.mse_loss(noise_pred.float(), noise.float(), reduction="mean")
```

### 5. Validation Function

#### âœ… Sá»­a Ä‘á»ƒ match vá»›i training logic:
- DÃ¹ng source image cho ControlNet vÃ  masked source
- DÃ¹ng color reference cho IP-Adapter
- Start tá»« random noise (nhÆ° inference)
- Generate vá»›i cÃ¡c conditions Ä‘Ãºng

### 6. Learning Rate Scheduler

#### âœ… ThÃªm:
```python
lr_scheduler = get_scheduler(
    args.lr_scheduler,
    optimizer=optimizer,
    num_warmup_steps=args.lr_warmup_steps * args.gradient_accumulation_steps,
    num_training_steps=len(train_dataloader) * args.num_train_epochs // args.gradient_accumulation_steps,
)

# Trong training loop:
lr_scheduler.step()
```

### 7. Checkpointing

#### âœ… Cáº£i thiá»‡n:
```python
# Save checkpoint má»—i 50 steps
if global_step > 0 and global_step % 50 == 0:
    checkpoint_dir = os.path.join(args.output_dir, f"checkpoint-{global_step}")
    accelerator.save_state(checkpoint_dir)

# Save final checkpoint
final_checkpoint_dir = os.path.join(args.output_dir, "checkpoint-final")
accelerator.save_state(final_checkpoint_dir)
```

### 8. Gradient Clipping

#### âœ… ThÃªm:
```python
if accelerator.sync_gradients:
    accelerator.clip_grad_norm_(unet.parameters(), 1.0)
```

---

## ğŸ“Š So SÃ¡nh Training Strategy

| Aspect | âŒ TrÆ°á»›c (SAI) | âœ… Sau (ÄÃšNG) |
|--------|----------------|----------------|
| **Noisy Input** | Source image (old wall) | **Target image (new wall)** |
| **ControlNet** | Source image | Source image âœ… |
| **IP-Adapter** | KhÃ´ng rÃµ | Color reference âœ… |
| **Masked Source** | KhÃ´ng rÃµ | Source image âœ… |
| **Target (GT)** | Source image (old) | **Target image (new)** |
| **Model há»c** | Reconstruct old color | **Generate new color** |

---

## ğŸ¯ Káº¿t Quáº£ Mong Äá»£i

Sau khi sá»­a, model sáº½:
1. âœ… Há»c generate mÃ u má»›i tá»« color reference
2. âœ… Preserve structure tá»« source image (ControlNet)
3. âœ… Transfer color tá»« reference (IP-Adapter)
4. âœ… Maintain context tá»« masked source (Inpainting)

---

## âš ï¸ LÆ°u Ã

1. **Dataset Keys**: Äáº£m báº£o dataset tráº£ vá» Ä‘Ãºng keys:
   - `target` (khÃ´ng pháº£i `targets`)
   - `mask` (khÃ´ng pháº£i `masks`)
   - `masked_sources` (khÃ´ng pháº£i `masked_source`)

2. **ControlNet Input**: ControlNet nháº­n depth map tá»« SOURCE image, khÃ´ng pháº£i target

3. **IP-Adapter Input**: IP-Adapter nháº­n color reference (new color), khÃ´ng pháº£i source image

4. **Masked Source**: DÃ¹ng SOURCE image vá»›i mask, khÃ´ng pháº£i target

---

## ğŸ§ª Testing

Äá»ƒ test training script:

```bash
python train.py \
    --data_json dataset_test/train/metadata.jsonl \
    --validation_json dataset_test/validation/metadata.jsonl \
    --output_dir output/test_training \
    --train_batch_size 2 \
    --num_train_epochs 1 \
    --resolution 512
```

Kiá»ƒm tra:
- âœ… Loss giáº£m dáº§n
- âœ… Validation images Ä‘Æ°á»£c generate
- âœ… Checkpoints Ä‘Æ°á»£c save
- âœ… KhÃ´ng cÃ³ errors

---

**TÃ¡c giáº£:** AI Assistant  
**NgÃ y:** 2026-02-07
